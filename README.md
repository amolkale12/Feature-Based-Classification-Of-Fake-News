# Feature-Based-Classification-Of-Fake-News
Social media is most common platform of newscast and the news credibility is the fact on the social media. The emerging technology bought the advantages in news generation and speed in broadcasting. Now a days news dissemination is very fast and accessibility at fingertips. As a result, unauthorized supply of news is increased and miss the nature of originality in content. Such undesirable news content cause hoax on social media and real life that affect individual and create bias in public opinion. News articles plays important role as it is the origin where people gather knowledge and create opinion about things based on news. The unwanted sources of news create question about things which not important or deceptive. Over this problem machine learning provide uncomplicated solution, at this juncture this research also contributes to the fake news classification. In this project feature-based classification approach is used based on the reliable and unreliable feature by using Support Vector Machine (SVM), AdaBoost Support Vector Machine (SVM), Logistic Regression, Multinomial Nave Bayes and Random Forest, ultimately controls the false news spread on the social media and maintain the news credibility.

#train as dataset file used in the project available as label data and categorize already by crowdsourcing.
We check the distribution of the different labeling used in the dataset and based on that we created the reliable and unreliable category for the different lables.
In reliable category we include true, most true and half true whereas in unreliable we include barely true and false labeled from the dataset.
To make things simpler we cerated two category to define the different lables which ultimately provide solution over class imbalance issue. The classes were indeed selected to be 2 and not any other specific set so as to tackle the problem of class imbalance, as the class distribution was highly skewed and to prevent the classifier from bias-variance tradeoff problems.

Naive Bayes classifier is used because it holds the assumption that the predictors are independent of each other which introduces high bias which is helpful to tackle the n >> p problem in text classification as the sample size is less as compared to the textual features generated (tfidf). Also it is a lot faster to train.
Random Forests were used so that chances are reduced upon a particular classifier fitting well on the train data and not that well on the test data I.e to overcome the problem of overfitting as the sample size was not that large.
Linear kernel SVM was used basically due to prevent overfitting(lot of features), is fast to train that other kernels like rbf, poly etc, also less hyper parameters to optimise, also textual data is often linearly separable. Same goes for Logistic Regression.

The F1-measures are almost same for all the classifier because the classifier was not able to differentiate between the two classes that effectively because the word count distribution was almost identical for both the classes. Also it is evident from the word clouds.

From the implemented models we can conclude that, Linear SVM and Logistic Regression models have achieved similar accuracy of .62, while the Random Forest and Nave Bayes models have slightly lower accuracy gures at .60. The ensemble approach of AdaBoost on SVM resulted in an low accuracy of .56, which is comparatively lower than the other models we have implemented. In the binary classication problem with
no evidence of data imbalance the F1 score is of signicance. From the table below the F1 score for Logistic Regression and Linear SVM is .71 for reliable classes and .45 for unreliable classes respectively. The measure of F1 score for Nave Bayes is skewed between
the reliable and unreliable classes, and low score for unreliable shows that its limitations at detecting unreliable data. As can be seen from the table, the measure of AUC ROC which shows the binary classication of the model, in our scenario Linear SVM, Logistic
Regression and Nave Bayes have achieved a score of .66 and AdaBoost had the least score of .62
